{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514d1a23",
   "metadata": {},
   "source": [
    "# Форматы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52abff7",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. \"Форматы данных\"\n",
    "* https://docs.python.org/3/library/json.html\n",
    "* https://docs.h5py.org/en/stable/\n",
    "* https://www.crummy.com/software/BeautifulSoup/bs4/doc.ru/bs4ru.html\n",
    "* Уэс Маккини. Python и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7670e",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47459cc",
   "metadata": {},
   "source": [
    "1. Вывести телефоны, содержащиеся в адресной книге `addres-book.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f43ac",
   "metadata": {},
   "source": [
    "2. По данным из файла `addres-book-q.xml` сформировать список словарей с телефонами каждого из людей. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f507d",
   "metadata": {},
   "source": [
    "3. Создайте 2 матрицы размера 1000x1000, используя различные параметризируемые распределения из numpy (https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html#distributions)\n",
    "\n",
    "После этого сохраните получившиеся матрицы в hdf5-файл в виде двух различных датасетов. В качестве описания каждого датасета укажите параметры используемых распределений "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc72c0",
   "metadata": {},
   "source": [
    "## Лабораторная работа №3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac60f59",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d80a7d",
   "metadata": {},
   "source": [
    "1.1 Считайте файл `contributors_sample.json`, воспользовавшись модулем `json` и свяжите загруженные данные с переменной `contributors`. Выведите на экран уникальные почтовые домены, содержащиеся в почтовых адресах людей. Под доменом понимается часть адреса, следующая за символом `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4fe069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    'contributors_sample.json', \n",
    "    'r',\n",
    "    encoding='utf-8'\n",
    ") as fp:\n",
    "    contributors = json.load(fp)\n",
    "#contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06898cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gmail.com', 'hotmail.com', 'yahoo.com'], dtype='<U20')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails = []\n",
    "a = []\n",
    "for person in contributors:\n",
    "    mails.append(person['mail'])\n",
    "mails\n",
    "for i in mails:\n",
    "    m = i.split('@')\n",
    "    a.append(m)\n",
    "a = np.array(a)\n",
    "np.unique(a[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef460b09",
   "metadata": {},
   "source": [
    "1.2 Посчитайте, как часто встречается та или иная должность во всем наборе данных. Выведите на экран 5 должностей, которые встречаются наиболее часто. Для каждого пользователя из `contributors` выясните, какая из его должностей является наиболее распространенной (в смысле частоты упоминания во всем датасете) и добавьте ключ `top_job`, в котором хранится название этой должности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48ebff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for person in contributors:\n",
    "    jobs.extend(ph for ph in person['jobs'])\n",
    "unique, counts = np.unique(jobs, return_counts=True)\n",
    "#print(unique, counts)\n",
    "\n",
    "res = np.column_stack([unique, counts])\n",
    "ress = res[res[:, 1].argsort()[::-1]][:5]\n",
    "#print(ress)\n",
    "###############################\n",
    "\n",
    "\n",
    "##########################\n",
    "top_job = []\n",
    "for person in contributors:\n",
    "    jb = []\n",
    "    jb1 = 0\n",
    "    jb2 = []\n",
    "    r = 0\n",
    "    for j in person['jobs']:\n",
    "        r = res[np.where(res == j),1][:1]\n",
    "        jb.append(r)\n",
    "        jb1 = max(jb)\n",
    "        jb2.append(j)\n",
    "        k = jb2[jb.index(jb1)]\n",
    "    top_job.append(k)\n",
    "#print(top_job)\n",
    "\n",
    "#dict1 = dict(zip(f, top_job))\n",
    "for i in range(len(contributors)):\n",
    "    contributors[i]['top_job'] = top_job[i]\n",
    "#contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff0c50",
   "metadata": {},
   "source": [
    "1.3 Создайте pd.DataFrame contributors_df, имеющий столбцы id, username и sex и n_jobs. Столбец n_jobs содержит кол-во должностей пользователя. При необходимости вы можете преобразовать исходные данные в списке contributors в удобный для создания pd.DataFrame вид.\n",
    "\n",
    "Сгруппируйте полученные данные по столбцам n_jobs и sex. Выведите на экран серию pd.Series, в которой содержится информация о количестве человек в каждой группе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19b95cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_jobs  sex\n",
      "3       F      703\n",
      "        M      690\n",
      "4       F      733\n",
      "        M      704\n",
      "5       F      700\n",
      "        M      670\n",
      "Name: jobs, dtype: int64\n",
      "//////////\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributors_df = pd.DataFrame(data = contributors)\n",
    "contributors_df = contributors_df.drop([\"name\"], axis = 1)\n",
    "contributors_df = contributors_df.drop([\"address\"], axis = 1)\n",
    "contributors_df = contributors_df.drop([\"mail\"], axis = 1)\n",
    "contributors_df['n_jobs'] = contributors_df['jobs'].str.len()\n",
    "contributors_df = contributors_df.groupby(['n_jobs','sex']).count()\n",
    "f = contributors_df.iloc[:,1]\n",
    "print(f)\n",
    "print('//////////')\n",
    "type(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f85ad",
   "metadata": {},
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffaeb6",
   "metadata": {},
   "source": [
    "2.1 По данным файла `steps_sample.xml` сформируйте словарь с шагами по каждому рецепту вида `{id_рецепта: [\"шаг1\", \"шаг2\"]}`. Сохраните этот словарь в файл `steps_sample.json`. Выведите на экран шаги рецепта с id `84797`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce92048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef519a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    'steps_sample.xml', \n",
    "    'r',\n",
    "    encoding='utf-8'\n",
    ") as fp:\n",
    "    xml = BeautifulSoup(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff1a3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12722cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e7d5455693e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrecipess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecipes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recipe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecipes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecipes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecipes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xml' is not defined"
     ]
    }
   ],
   "source": [
    "recipess = {}\n",
    "recipes = xml.find_all('recipe')\n",
    "for i in range(len(recipes)):\n",
    "    id = recipes[i].find_all('id')\n",
    "    steps = recipes[i].find_all('step')\n",
    "    steps = [steps[j].text for j in range(len(steps))]\n",
    "    recipess[id[0].text] = recipess.get(id[0].text, steps)\n",
    "#recipess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef150b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('steps_sample.json', 'w') as fp:\n",
    "    json.dump(recipess, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca6e4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    'steps_sample.json', \n",
    "    'r',\n",
    "    encoding='utf-8'\n",
    ") as fp:\n",
    "    steps_sample = json.load(fp)\n",
    "#steps_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0f840fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honey mustard sauce: whisk all the ingredients together serve warm or cold',\n",
       " 'easy bbq sauce: combine all ingredients in a pot& cook over low heat until the sugar is dissolved',\n",
       " 'serve warm or cold',\n",
       " 'garlic dill sauce: mix all the ingredients and chill until ready to serve']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipess['84797']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1653ec0",
   "metadata": {},
   "source": [
    "2.2 Получите список идентификаторов рецептов, в этапах выполнения которых есть информация о времени (часы или минуты). Для отбора подходящих рецептов обратите внимание на атрибуты соответствующих тэгов. Выведите на экран количество таких рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377f2bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22437"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = set()\n",
    "\n",
    "recipes = xml.find_all('recipe')\n",
    "def get_key(d, value):  #узнаёт ключ, словаря с известным значением \n",
    "    for k, v in d.items():\n",
    "        if v == value:\n",
    "            return k\n",
    "\n",
    "for i in range(len(recipes)):\n",
    "    idd = recipes[i].find_all('id')\n",
    "    steps = recipes[i].find_all('step')\n",
    "    for step in steps:\n",
    "        if (get_key(step.attrs, '1') ==  'has_minutes') or (get_key(step.attrs, '1') == 'has_hours'):\n",
    "            rec.add(idd[0].text)\n",
    "len(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f68cb",
   "metadata": {},
   "source": [
    "2.3 Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в таблицу `recipes`. Для строк, которые содержат пропуски в столбце `n_steps`, заполните этот столбец на основе файла  `steps_sample.xml`. Строки, в которых столбец `n_steps` заполнен, оставьте без изменений. При решении задачи не используйте метод `iterrows` и аналогичные ему, позволяющие итерироваться по таблице построчно.\n",
    "\n",
    "Проверьте, содержит ли столбец `n_steps` пропуски. Если нет, то преобразуйте его к целочисленному типу и сохраните результаты в файл `recipes_sample_with_filled_nsteps.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35f1e5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44123</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67664</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>10</td>\n",
       "      <td>91970</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38798</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>30</td>\n",
       "      <td>1533</td>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>these were so go, it surprised even me.</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35173</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>45</td>\n",
       "      <td>22724</td>\n",
       "      <td>2002-07-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister-in-law made these for us at a family...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84797</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>25</td>\n",
       "      <td>4470</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267661</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>80</td>\n",
       "      <td>200862</td>\n",
       "      <td>2007-11-25</td>\n",
       "      <td>16.0</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386977</th>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>240</td>\n",
       "      <td>177443</td>\n",
       "      <td>2009-08-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is a traditional fresh plum cake, thought...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103312</th>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>75</td>\n",
       "      <td>161745</td>\n",
       "      <td>2004-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is a traditional late summer early fall s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486161</th>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>60</td>\n",
       "      <td>227978</td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is a delicious soup that i originally fou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298512</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>29</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>9.0</td>\n",
       "      <td>i've heard of the 'cookies by design' company,...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  minutes  contributor_id  \\\n",
       "id                                                                              \n",
       "44123          george s at the cove  black bean soup       90           35193   \n",
       "67664             healthy for them  yogurt popsicles       10           91970   \n",
       "38798                   i can t believe it s spinach       30            1533   \n",
       "35173                           italian  gut busters       45           22724   \n",
       "84797       love is in the air  beef fondue   sauces       25            4470   \n",
       "...                                              ...      ...             ...   \n",
       "267661  zurie s holey rustic olive and cheddar bread       80          200862   \n",
       "386977          zwetschgenkuchen  bavarian plum cake      240          177443   \n",
       "103312   zwiebelkuchen   southwest german onion cake       75          161745   \n",
       "486161                                   zydeco soup       60          227978   \n",
       "298512        cookies by design   cookies on a stick       29          506822   \n",
       "\n",
       "         submitted  n_steps  \\\n",
       "id                            \n",
       "44123   2002-10-25      NaN   \n",
       "67664   2003-07-26      NaN   \n",
       "38798   2002-08-29      NaN   \n",
       "35173   2002-07-27      NaN   \n",
       "84797   2004-02-23      4.0   \n",
       "...            ...      ...   \n",
       "267661  2007-11-25     16.0   \n",
       "386977  2009-08-24      NaN   \n",
       "103312  2004-11-03      NaN   \n",
       "486161  2012-08-29      NaN   \n",
       "298512  2008-04-15      9.0   \n",
       "\n",
       "                                              description  n_ingredients  \n",
       "id                                                                        \n",
       "44123   an original recipe created by chef scott meska...           18.0  \n",
       "67664   my children and their friends ask for my homem...            NaN  \n",
       "38798             these were so go, it surprised even me.            8.0  \n",
       "35173   my sister-in-law made these for us at a family...            NaN  \n",
       "84797   i think a fondue is a very romantic casual din...            NaN  \n",
       "...                                                   ...            ...  \n",
       "267661  this is based on a french recipe but i changed...           10.0  \n",
       "386977  this is a traditional fresh plum cake, thought...           11.0  \n",
       "103312  this is a traditional late summer early fall s...            NaN  \n",
       "486161  this is a delicious soup that i originally fou...            NaN  \n",
       "298512  i've heard of the 'cookies by design' company,...           10.0  \n",
       "\n",
       "[30000 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_csv('recipes_sample.csv', sep = ',')\n",
    "recipes = recipes.set_index('id')\n",
    "recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d78a2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd= []\n",
    "file = open(\"steps_sample.xml\",\"r\").read()\n",
    "soup = BeautifulSoup(file,'xml')\n",
    "for recipe in soup.find_all('recipe'):\n",
    "    recipe_id= int(recipe.find(\"id\").get_text())\n",
    "    steps_count= len(recipe.find_all(\"step\"))\n",
    "    dd.append(steps_count)\n",
    "#dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e296183",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['n_steps'].where(recipes['n_steps'].isnull(), dd, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "211f8ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ab78538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes['n_steps'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1da45b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "44123     11\n",
       "67664      3\n",
       "38798      5\n",
       "35173      7\n",
       "84797      4\n",
       "          ..\n",
       "267661    16\n",
       "386977    22\n",
       "103312    10\n",
       "486161     7\n",
       "298512     9\n",
       "Name: n_steps, Length: 30000, dtype: int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes['n_steps'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bce67514",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.to_csv('recipes_sample_with_filled_nsteps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd86e69",
   "metadata": {},
   "source": [
    "### hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde1ab6",
   "metadata": {},
   "source": [
    "3.1 Выведите названия всех датасетов, находящихся в файле `nutrition_sample.h5`, а также размерность матриц, содержащихся в данных датасетах и их метаданные.\n",
    "\n",
    "Формат вывода:\n",
    "```\n",
    "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#)\n",
    "Dataset name=dataset_1 n_rows=30000 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
    "Dataset name=dataset_2 n_rows=30000 n_cols=2 col_0=recipe_id col_1=sugar (PDV)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "377bf42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"dataset_0\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'calories (#)'}\n",
      "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#) \n",
      "<HDF5 dataset \"dataset_1\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}\n",
      "Dataset name=dataset_1 n_rows=30000 n_cols=2 col_0=recipe_id col_1=total fat (PDV) \n",
      "<HDF5 dataset \"dataset_2\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}\n",
      "Dataset name=dataset_2 n_rows=30000 n_cols=2 col_0=recipe_id col_1=sugar (PDV) \n",
      "<HDF5 dataset \"dataset_3\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}\n",
      "Dataset name=dataset_3 n_rows=30000 n_cols=2 col_0=recipe_id col_1=sodium (PDV) \n",
      "<HDF5 dataset \"dataset_4\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}\n",
      "Dataset name=dataset_4 n_rows=30000 n_cols=2 col_0=recipe_id col_1=protein (PDV) \n",
      "<HDF5 dataset \"dataset_5\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}\n",
      "Dataset name=dataset_5 n_rows=30000 n_cols=2 col_0=recipe_id col_1=saturated fat (PDV) \n",
      "<HDF5 dataset \"dataset_6\": shape (30000, 2), type \"<f8\">\n",
      "{'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}\n",
      "Dataset name=dataset_6 n_rows=30000 n_cols=2 col_0=recipe_id col_1=carbohydrates (PDV) \n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "with h5py.File(\"nutrition_sample.h5\", \"r\") as hf:\n",
    "    for key in hf.keys():\n",
    "        file = hf[key]\n",
    "        metadata = dict(file.attrs)\n",
    "        print(f\"Dataset name={key} n_rows={file.shape[0]} n_cols={file.shape[1]} col_0={metadata['col_0']} col_1={metadata['col_1']} \")\n",
    "        dataset[key] = {'all_data' : {'data': file[:]}, 'attrs': metadata}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b81f9c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('dataset_0', {'all_data': {'data': array([[4.41230e+04, 8.04700e+02],\n",
       "       [6.76640e+04, 1.64600e+02],\n",
       "       [3.87980e+04, 5.38000e+01],\n",
       "       ...,\n",
       "       [1.03312e+05, 8.64100e+02],\n",
       "       [4.86161e+05, 4.15200e+02],\n",
       "       [2.98512e+05, 1.88000e+02]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'calories (#)'}}), ('dataset_1', {'all_data': {'data': array([[4.41230e+04, 1.08000e+02],\n",
       "       [6.76640e+04, 3.00000e+00],\n",
       "       [3.87980e+04, 5.00000e+00],\n",
       "       ...,\n",
       "       [1.03312e+05, 8.70000e+01],\n",
       "       [4.86161e+05, 2.60000e+01],\n",
       "       [2.98512e+05, 1.10000e+01]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}}), ('dataset_2', {'all_data': {'data': array([[4.41230e+04, 2.60000e+01],\n",
       "       [6.76640e+04, 5.00000e+00],\n",
       "       [3.87980e+04, 2.00000e+00],\n",
       "       ...,\n",
       "       [1.03312e+05, 3.00000e+01],\n",
       "       [4.86161e+05, 3.40000e+01],\n",
       "       [2.98512e+05, 5.70000e+01]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}}), ('dataset_3', {'all_data': {'data': array([[4.41230e+04, 1.90000e+01],\n",
       "       [6.76640e+04, 1.00000e+00],\n",
       "       [3.87980e+04, 3.00000e+00],\n",
       "       ...,\n",
       "       [1.03312e+05, 1.80000e+01],\n",
       "       [4.86161e+05, 2.60000e+01],\n",
       "       [2.98512e+05, 1.10000e+01]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}}), ('dataset_4', {'all_data': {'data': array([[4.41230e+04, 2.80000e+01],\n",
       "       [6.76640e+04, 4.00000e+00],\n",
       "       [3.87980e+04, 3.00000e+00],\n",
       "       ...,\n",
       "       [1.03312e+05, 4.00000e+01],\n",
       "       [4.86161e+05, 4.40000e+01],\n",
       "       [2.98512e+05, 7.00000e+00]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}}), ('dataset_5', {'all_data': {'data': array([[4.41230e+04, 2.14000e+02],\n",
       "       [6.76640e+04, 6.00000e+00],\n",
       "       [3.87980e+04, 3.00000e+00],\n",
       "       ...,\n",
       "       [1.03312e+05, 1.52000e+02],\n",
       "       [4.86161e+05, 2.10000e+01],\n",
       "       [2.98512e+05, 2.10000e+01]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}}), ('dataset_6', {'all_data': {'data': array([[4.41230e+04, 1.00000e+01],\n",
       "       [6.76640e+04, 1.10000e+01],\n",
       "       [3.87980e+04, 1.00000e+00],\n",
       "       ...,\n",
       "       [1.03312e+05, 2.30000e+01],\n",
       "       [4.86161e+05, 1.50000e+01],\n",
       "       [2.98512e+05, 9.00000e+00]])}, 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}})])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc9790",
   "metadata": {},
   "source": [
    "3.2 Разбейте каждый из имеющихся датасетов на две части: 1 часть содержит только те строки, где PDV (Percent Daily Value) превышает 100%; 2 часть содержит те строки, где PDV составляет не более 100%. Создайте 2 группы в файле и разместите в них соответствующие части датасета c сохранением метаданных исходных датасетов. Итого должно получиться 2 группы, содержащие несколько датасетов. Датасеты, которые не содержат информацию о PDV, оставьте вне групп. Сохраните результаты в файл `nutrition_grouped.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f500ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PDV>100': {'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n",
      "       [6.76640e+04, 3.00000e+00],\n",
      "       [3.87980e+04, 5.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 8.70000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n",
      "       [6.76640e+04, 5.00000e+00],\n",
      "       [3.87980e+04, 2.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 3.00000e+01],\n",
      "       [4.86161e+05, 3.40000e+01],\n",
      "       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n",
      "       [6.76640e+04, 1.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.80000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n",
      "       [6.76640e+04, 4.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 4.00000e+01],\n",
      "       [4.86161e+05, 4.40000e+01],\n",
      "       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n",
      "       [6.76640e+04, 6.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.52000e+02],\n",
      "       [4.86161e+05, 2.10000e+01],\n",
      "       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n",
      "       [6.76640e+04, 1.10000e+01],\n",
      "       [3.87980e+04, 1.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 2.30000e+01],\n",
      "       [4.86161e+05, 1.50000e+01],\n",
      "       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}, 'PDV<100': {'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n",
      "       [6.76640e+04, 3.00000e+00],\n",
      "       [3.87980e+04, 5.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 8.70000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n",
      "       [6.76640e+04, 5.00000e+00],\n",
      "       [3.87980e+04, 2.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 3.00000e+01],\n",
      "       [4.86161e+05, 3.40000e+01],\n",
      "       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n",
      "       [6.76640e+04, 1.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.80000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n",
      "       [6.76640e+04, 4.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 4.00000e+01],\n",
      "       [4.86161e+05, 4.40000e+01],\n",
      "       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n",
      "       [6.76640e+04, 6.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.52000e+02],\n",
      "       [4.86161e+05, 2.10000e+01],\n",
      "       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n",
      "       [6.76640e+04, 1.10000e+01],\n",
      "       [3.87980e+04, 1.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 2.30000e+01],\n",
      "       [4.86161e+05, 1.50000e+01],\n",
      "       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}}\n",
      "{'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n",
      "       [6.76640e+04, 3.00000e+00],\n",
      "       [3.87980e+04, 5.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 8.70000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n",
      "       [6.76640e+04, 5.00000e+00],\n",
      "       [3.87980e+04, 2.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 3.00000e+01],\n",
      "       [4.86161e+05, 3.40000e+01],\n",
      "       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n",
      "       [6.76640e+04, 1.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.80000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n",
      "       [6.76640e+04, 4.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 4.00000e+01],\n",
      "       [4.86161e+05, 4.40000e+01],\n",
      "       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n",
      "       [6.76640e+04, 6.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.52000e+02],\n",
      "       [4.86161e+05, 2.10000e+01],\n",
      "       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n",
      "       [6.76640e+04, 1.10000e+01],\n",
      "       [3.87980e+04, 1.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 2.30000e+01],\n",
      "       [4.86161e+05, 1.50000e+01],\n",
      "       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}\n",
      "{'PDV>100': {'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n",
      "       [6.76640e+04, 3.00000e+00],\n",
      "       [3.87980e+04, 5.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 8.70000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n",
      "       [6.76640e+04, 5.00000e+00],\n",
      "       [3.87980e+04, 2.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 3.00000e+01],\n",
      "       [4.86161e+05, 3.40000e+01],\n",
      "       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n",
      "       [6.76640e+04, 1.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.80000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n",
      "       [6.76640e+04, 4.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 4.00000e+01],\n",
      "       [4.86161e+05, 4.40000e+01],\n",
      "       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n",
      "       [6.76640e+04, 6.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.52000e+02],\n",
      "       [4.86161e+05, 2.10000e+01],\n",
      "       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n",
      "       [6.76640e+04, 1.10000e+01],\n",
      "       [3.87980e+04, 1.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 2.30000e+01],\n",
      "       [4.86161e+05, 1.50000e+01],\n",
      "       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}, 'PDV<100': {'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n",
      "       [6.76640e+04, 3.00000e+00],\n",
      "       [3.87980e+04, 5.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 8.70000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n",
      "       [6.76640e+04, 5.00000e+00],\n",
      "       [3.87980e+04, 2.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 3.00000e+01],\n",
      "       [4.86161e+05, 3.40000e+01],\n",
      "       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n",
      "       [6.76640e+04, 1.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.80000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n",
      "       [6.76640e+04, 4.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 4.00000e+01],\n",
      "       [4.86161e+05, 4.40000e+01],\n",
      "       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n",
      "       [6.76640e+04, 6.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.52000e+02],\n",
      "       [4.86161e+05, 2.10000e+01],\n",
      "       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n",
      "       [6.76640e+04, 1.10000e+01],\n",
      "       [3.87980e+04, 1.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 2.30000e+01],\n",
      "       [4.86161e+05, 1.50000e+01],\n",
      "       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}}\n",
      "{'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n",
      "       [6.76640e+04, 3.00000e+00],\n",
      "       [3.87980e+04, 5.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 8.70000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n",
      "       [6.76640e+04, 5.00000e+00],\n",
      "       [3.87980e+04, 2.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 3.00000e+01],\n",
      "       [4.86161e+05, 3.40000e+01],\n",
      "       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n",
      "       [6.76640e+04, 1.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.80000e+01],\n",
      "       [4.86161e+05, 2.60000e+01],\n",
      "       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n",
      "       [6.76640e+04, 4.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 4.00000e+01],\n",
      "       [4.86161e+05, 4.40000e+01],\n",
      "       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n",
      "       [6.76640e+04, 6.00000e+00],\n",
      "       [3.87980e+04, 3.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 1.52000e+02],\n",
      "       [4.86161e+05, 2.10000e+01],\n",
      "       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n",
      "       [6.76640e+04, 1.10000e+01],\n",
      "       [3.87980e+04, 1.00000e+00],\n",
      "       ...,\n",
      "       [1.03312e+05, 2.30000e+01],\n",
      "       [4.86161e+05, 1.50000e+01],\n",
      "       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}\n"
     ]
    }
   ],
   "source": [
    "dataset= {data : info for data, info in dataset.items() if \"PDV\" in info[\"attrs\"][\"col_1\"]}\n",
    "\n",
    "update_dataset= {\"PDV>100\" : {}, \"PDV<100\": {}}\n",
    "for datasets, val in dataset.items():\n",
    "    data= val[\"all_data\"][\"data\"]\n",
    "    update_dataset[\"PDV>100\"][datasets] = {\"data\" :  data, \"attrs\" : val[\"attrs\"], \"name\": datasets}\n",
    "    update_dataset[\"PDV<100\"][datasets] = {\"data\" :  data, \"attrs\" : val[\"attrs\"], \"name\": datasets}\n",
    "    \n",
    "for datasets, data in update_dataset.items():\n",
    "    print(update_dataset)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65dba9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('nutrition_grouped.h5', 'w') as f:\n",
    "    for datasets, data in update_dataset.items():\n",
    "            gg = f.create_group(datasets)\n",
    "            for j in data:\n",
    "                data1 = gg.create_dataset(name = data[j]['name'], data = data[j]['data'])\n",
    "                data1.attrs.update(data[j]['attrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1973f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"dataset_3\": shape (30000, 2), type \"<f8\">\n",
      "Dataset [[4.41230e+04 1.08000e+02]\n",
      " [6.76640e+04 3.00000e+00]\n",
      " [3.87980e+04 5.00000e+00]\n",
      " ...\n",
      " [1.03312e+05 8.70000e+01]\n",
      " [4.86161e+05 2.60000e+01]\n",
      " [2.98512e+05 1.10000e+01]]\n",
      "<HDF5 dataset \"dataset_3\": shape (30000, 2), type \"<f8\">\n",
      "Dataset [[4.41230e+04 1.08000e+02]\n",
      " [6.76640e+04 3.00000e+00]\n",
      " [3.87980e+04 5.00000e+00]\n",
      " ...\n",
      " [1.03312e+05 8.70000e+01]\n",
      " [4.86161e+05 2.60000e+01]\n",
      " [2.98512e+05 1.10000e+01]]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\n",
    "    'nutrition_grouped.h5',\n",
    "    'r'\n",
    "    ) as hdf:\n",
    "    #print(hdf.items())\n",
    "    for key in hdf.keys():\n",
    "        file = hdf[key]\n",
    "        metadata = dict(file.attrs)\n",
    "        print(file['dataset_3'])\n",
    "        print('Dataset',file['dataset_1'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0bb67a",
   "metadata": {},
   "source": [
    "3.3 Выведите названия всех групп и датасетов, находящихся в этих группах, из файла `nutrition_grouped.h5` а также размерность матриц, содержащихся в датасетах и их метаданные.\n",
    "\n",
    "Формат вывода:\n",
    "```\n",
    "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#)\n",
    "Group less_equal_than_100:\n",
    "    Dataset name=less_equal_than_100/dataset_1 n_rows=28264 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
    "    ....\n",
    "Group more_than_100\n",
    "    Dataset name=more_than_100/dataset_1 n_rows=1736 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
    "    ....\n",
    "....\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
